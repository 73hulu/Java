# 内存模型

题目中的“内存模型”和JVM运行时内存划分是完全不同的！

Java内存模型（即Java Memory Model, 简称JMM）是一种抽象的概念，它描述的是一组控制程序中各个变量在共享数据区域和私有数据区域的访问方式的**规则**。没错，对应于JVM运行时内存，这里的“共享数据区域”可以理解为堆和方法区，而“私有数据区域”可以理解为栈（包括Java方法栈和Native栈）和程序计数器。

## JMM
JMM并不是一个割裂的概念，我们还需要了解硬件内存架构和JVM中线程实现原理。
### JMM
我们知道JVM运行程序的实体是线程，而每个线程创建的时候JVM都会为创建一个**工作区域**（对应于栈帧），用来存储线程的私有数据。这些数据哪里来呢? 有一部分是自己本身，还有一部分来自于主内存（对应于堆和方法区），而主内存是共享的，所有的线程都可以访问。但是线程对变量的操作（读取赋值等）必须在主存中进行。所以JMM就控制产生了这样的工作常见：线程首先读取主存内的共享变量，将其拷贝一个副本到自己的工作内存中并进行操作，然后将变量写回到主内存。

这种方式就如下图所示：

![JMM](https://ws1.sinaimg.cn/large/006tNc79gy1fthzikoutkj30lp0dywjg.jpg)


上图中出现两个名词：工作内存和主内存。可以将其分别理解对应为JVM运行时内存分区中的栈和堆及方法区，那么它们中存储的数据类型以及操作方式也就很明了了：

* 对于一个实例对象中**成员方法**而言，如果方法中包含本地变量是基本数据类型，就直接存储在工作内存的栈帧结构中，但是倘若本地变量是引用类型，那么变量的引用会存储在栈帧中，而对象实例将存储在主内存中。

* 对于一个实例对象的成员变量，不管它是基本数据类型还是引用类型，都会被存储到堆区域。
* static变量以及本身信息都会存储在主内存中。

所以，如果主内存中的实例被多个线程所引用，那么它在不同的线程工作内存中都有不同的拷贝。

![JVM](https://ws4.sinaimg.cn/large/006tNc79gy1fthzpy9txaj30jx0h478w.jpg)


### 硬件内存机构
说完Java内存模型，接下来我们来聊一聊硬件内存架构。

Java硬件架构的简易图如下：
![硬件内存架构](https://ws2.sinaimg.cn/large/006tNc79gy1fti08lzva1j30hi0an40a.jpg)

目前的计算机而言。一般拥有多个CPU并且每个CPU可能存在多核（多核是指一个CPU上有多个完整的计算引擎，即内核，这样就能支持多任务并行执行）。从多线程的调度来看，每个线程都会映射到各个CPU核心中进行并行运算。在CPU内部有一组CPU寄存器，寄存器是存放CPU能直接访问和处理的数据的一个临时的空间。这部分的数据从哪里来呢？从主存拷贝来。但是相对于CPU来说，它IO的速度实在是太慢了，以至于CPU在从主存中取数据时候，需要花很多的时间在等待内存做准备工作上。为了姐姐这个问题，CPU寄存器和主存之间加入了CPU缓存。当CPU访问主存时，会限度去一部分主存数据到CPU缓存（当然如果缓存中命中了数据，就会从缓存中直接读取），进而再读取CPU缓存到寄存器。当CPU需要写数据到主存时，同样会先刷新寄存器中的数据到CPU缓存，然后将在缓存中的数据刷新到主内存中。

说到这里，很容易就能想到一个问题，既然每个CPU处理的数据都是主内存的一个拷贝，那么如果两个CPU同时对主存中的一个数据进行拷贝，然后做了不同的处理，最后同时写回主内存，最后的结果是什么？答案是不一定。这就是所谓的**缓存不一致**问题。此时，被多个线程访问的变量称为**共享变量**。

为了解决缓存不一致问题，一般来说有两种解决办法：
1. 在总线上就爱上LOCK#锁的方式： 因为CPU和其他部件之间的通信都是通过总线来进行的，如果总线上加上LOCK#锁，那么就阻塞了其他CPU对其他部件的访问（比如主存），从而只有一个CPU能访问这个变量的主存。问题虽然解决了，但是由于在锁住总线期间，其他CPU无法访问主存，导致效率底下。
2. 通过缓存一致性协议：最出名的就是Intel的MESI协议。MESI协议保证了每个缓存中使用的共享变量的副本是一致的。其核心思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU也存在该变量的副本，会发出信号通知其他CPU将该变量的**缓存**置为无效状态，因此，当其他CPU需要读取这个变量时，发现自己缓存中该变量的缓存是无效的，那么就会从主存中读取。

> 读到这里，突然领悟了过来，Java中的锁和volatile不就分别对应了这两种方式么。

![硬件内存架构中缓存不一致问题的解决](https://ws1.sinaimg.cn/large/006tNc79gy1ftidxzbd41j30l909rgme.jpg)

### JVM中线程实现原理

接着我们需要了解一下JVM中线程的实现原理。

在Window和Linux系统上，Java线程的实现是一对一模型，即通** 语言层面 ** 层面去间接调用系统内核的线程模型。即Java线程是最终是通过调用操作系统的内核线程完成的。

> 内核线程（KT）, 是操作系统内核支持的线程，这种线程由操作系统内核来完成线程切换，内核通过操作系统进而对象线程执行调度，并将线程的任务映射到各个处理器上。这就是操作系统可以处理多任务的原因。

我们Java编写的线程是语言层级的，实际上是一种**轻量级进程**，注意是进程而不是线程，也是我们通常意义上的线程。每个轻量级线程都会被映射到一个内核线程，因此我们可以通过通过轻量级进程调用内核线程，进而由操作系统内核将任务映射到各个任务处理区，这种轻量级进程与内核线程之间一对一的关系就称为**一对一的线程模型**。

![一对一的线程模型](https://ws4.sinaimg.cn/large/006tNc79gy1ftid47a3vqj30i60i2n2w.jpg)

所以最终，每个线程都会被映射到CPU中进行处理，如果CPU存在多核，那么一个CPU将可以并行执行多个线程任务。

### JMM和硬件内存架构的关系
仔细看上文JMM和硬件内存架构的图，发现两者好像非常相似。但是实际上，两者并不并不完全一致。

对于硬件内存架构来说只有寄存器、缓存内存和主存的概念，并没有工作内存和主存之分。那当然了，工作内存和主存只是一种抽象概念，实际上并不存在。

硬件内存架构和JMM是一个相互交叉的关系，是一种真是硬件物理硬件和抽象概念划分的交叉（Java内存区域划分也是同样的道理）。
![JMM内存模型与硬件内存架构的关系](https://ws1.sinaimg.cn/large/006tNc79gy1ftidm8g8xmj30p30cojvp.jpg)


讲到这里，大概对JMM有了基本的概念，还没完，接下来我们先跳出JMM，先看看并发编程中遇到的三个问题，然后我们再学习JMM如何保证这三个问题的解决。

## JMM的承诺
JVM内存模型有三个承诺：原子性、可见性和有序性，这也是并发编程中经常遇到的问题：
### 原子性
原子性的含义是：一个操作或多个操作，要么全部执行并且整个过程不会被任何因素打断，要么就不执行。

原子性经常拿银行转账的例子来说明，这里就不赘述了。需要注意的是，对于32位的系统来说，long类型和double是64位的，他们的读写并非原子性的（但是基本数据类型的操作是原子性的），因为对于32位的虚拟机来说，每次原子读写都是32位，这样对于64位的操作，完成前32位的原子操作后，轮到另一个线程读取时候，恰好读取到后32位的数据，这样可能会读到一个既非原值也不是线程修改至的情况。当然这种情况非常少发生。

### 可见性
可见性的含义是：当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看到修改的值。举个例子：
```java
// 线程1执行的代码
int i = 0;
i = 10;

// 线程2执行的代码
j = i;
```
若干线程1和2分别被CPU1和2分别执行。当线程1执行`i = 10`这句话时，会把i的初始值加载到CPU1的高速缓存中，赋值为10，但是并没有立即被写回主存。

此时线程2执行`j = i`，它会先去读取主存i的值并加载到CPU2的缓存中，注意此时主存中`i`的值为0，并不是10。这样得到的`j`的值是0而不是10。

这就是可见性问题，线程1对变量i的修改并没有立即被线程2看到。

### 有序性
有序性的含义是：程序执行的顺序按照代码的先后顺序执行。

我们总认为代码的执行是按照顺序依次执行的，这并没有什么毛病。对于单线程是这样的，但是在多线程环境中，可能就会出现乱序现象，因为程序编译成机器码指令后可能会出现指令重排现象。

指令重排是一种提高计算机执行新能的手段。一般有以下3种：
* 编译器优化的重排（属于编译器重排）：编译器在不改变单线程语义的前提下，可以重新安排语句的执行顺序。
* 指令并行的重排（属于处理器重排）：现代处理器采用了指令级并行技术来讲多条指令重叠执行。如果不存在数据依赖（即后一个执行的语句无需依赖前面执行的语句的结构），处理器可以改变语句对应的机器指令的执行顺序。
* 内存系统的重排（属于处理器重排）：由于处理器使用缓存和读写缓冲区，这使得加载(load)和存储(store)操作看上去可能是乱序执行，因为三级缓存的存在，倒置内存与缓存的数据同步存在时间差。

这两种重排的具体示例可以查看这篇[博文](https://blog.csdn.net/javazejian/article/details/72772461)，里面的例子讲的非常清楚。

**指令重排只会保证单线程中串行语义的执行的一致性，但是并不关心多线程间的语义一致性**。

## JMM的解决方案
下面我们讨论一下JMM如何兑现承诺。
### 原子性
在Java中，对基本数据类型的变量的**读取**和**赋值**是原子性操作。看下面的例子：
```java
x = 10; // ①
y = x; // ②
x ++; // ③
x = x + 1; // ④
```
上面四个语句，实际上只有语句语句①才是原子的，其他三个都不是原子的。
语句②实际上包含2个操作：先读取，然后写入工作内存。虽然这两个操作本身是原子的，但是合起来就不是原子的了。
语句③和语句④都包含3个操作：读取，加1操作，写回新值

所以说，**JMM内存模型只保证基本读取和赋值是原子操作**，如果要实现更大范围的原子性，**可以通过`synchronized`和`lock`来实现**，

### 可见性
Java提供了**volatile**关键字来保证可见性。

volatile修饰的变量是共享变量，它保证修改的值会立即被更新到主存，当其他线程需要读取的时，它会到内存中读取新值。

而没有被volatile修饰的变量不能保证可见性。因为普通共享变量被修改后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，无法保证可见性。

另外，synchronized和lock也能保证可见性，因为synchronized和lock保证了同一时刻只有一个现场层获取锁然后执行同步代码，并且会释放锁之前会将对变量的修改刷新到主存当中。

### 有序性
指令重排可能会影响到多线程的并发执行结果的正确性。在Java里面，可以通过volatile关键字来保证一定的有序性。另外synchornized和lock也能保证有序性。因为同一时刻只有一个线程执行代码，相当于让线程顺序执行同步代码，自然就保证了有序性。

另外，java中也有一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常被称为“**happens-before原则**”，**如果两个操作无法从happens-before原则推导出来，那么它们就不能保证有序性，虚拟机可以随意对它们进行重排序。**

happens-before原则一共8条规则：
1. 程序次序原则：一个线程内，按照代码顺序，书写在前面的操作先发生于书写在后面的操作。
2. 锁定规则：一个unlock操作先行发生于后面对同一个锁的lock操作。
3. **volatitle变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作。**
4. 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，那么操作A先行发生于操作C。
5. 线程启动规则：Thread对象的start()方法先行发生于此线程的每一个动作
6. 线程中断规则：对线程`interrupt()`方法的调用先行发生于被中断线程的代码检测到的中断的发生
7. 对象终结规则：一个对象初始化完成先行发生于它的`finalize()`方法的开始。

这8条规则细想一下都是显而易见、符合逻辑的。尤其注意第3条，volatile是接下来关注的重点。

## volatitle的内存语义
volatile是Java虚拟机提供的轻量级的同步机制。其作用有两个：
1. 保证被`volatile`修饰的共享变量对所有线程总是可见的，也就是当一个线程修改了一个被volatitle修饰的共享变量的值，新值总是可以被其他线程立即得知。
2. 禁止指令重排序。

### volatile的可见性
volatile能保证多线程环境下共享变量的可见性，但是不能保证原子性，比如下面这种情况：
```java
public class VolatitleVisibility{
  public static volatile int i = 0;

  public static void increase(){
    i ++;
  }
}
```
正如上述代码所示，`i`变量的任何改变都能立即被反映到其他线程中，但是如果存在多条线程同时调用`increase()`方法的话，就会出现线程安全问题，毕竟`i++`不具备原子性。`i++`一共分为读操作和加1操作，如果第二个线程在第一个线程读取旧值和写回新值期间读取`i`的域值，那么第二个线程就会在与第一个线程一期看到同一个值，并且都执行加1操作，这也就造成了线程安全失败。因此对于`increase()`方法必须使用`synchornized`修饰，以保证线程安全。但是使用`synchornized`修饰后，由于`synchornized`本身也具备与`volatile`相同的性质，即可见性，此时就可以省略`volatile`关键字：
```Java
public class VolatitleVisibility{
  public static int i = 0;
  public synchornized static void increase(){
    i ++;
  }
}
```
但是对原子性的操作，`volatile`是能够保证线程安全的。比如：
```Java
publci class VolatileSafe{
  volatile boolean close;

  public void close(){
    close = true;
  }

  public void doWord(){
    while(!close){
      System.out.println("safe ....");
    }
  }
}
```
由于`close = true`是原子性操作，因此可以通过`volatile`修饰来达到线程安全的目的。实际上，当写一个`volatile`变量时，JMM会把线程对应的工作内存中的共享变量值刷新到主内存中，当读取一个`volatile`变量时，JMM会把该线程对应的工作内存置为无效，那么该线程将只能从主内存中重新读取共享变量。这种方式背后的原理是**内存屏障**，稍后会说明。

### volatile组织重排优化
首先需要了解一个概念：内存屏障（Memory Barrier）。

内存屏障，又叫内存栅栏，是一个CPU指令，有两个作用：
①保证特定操作的执行顺序。
②保证某些变量的内存可见性（利用该特性实现volatile的内存可见性）
如果在CPU之间插入一条Memory Barrier，就会告诉编译器和CPU，不管什么指令都不能和这条Memory Barrier指令重排序，即通过插入内存屏障，禁止在内存屏障前后的指令执行重排序优化。

Memory Barrier的另外一个作用是强制刷出各种CPU的缓存数据，因此任何CPU上的线程都能读取到这些数据的最新版本。

下面看一个典型的禁止重排优化的例子DCL：
```java

public class DoubleCheckLock{

  private statci DoubleCheckLock instance;

  private DoubleCheckLock(){}

  public static DoubleCheckLock getInstance(){
    // 第一次检测
    if (Objects.isNull(instance)) {
      // 同步
      synchornized (DoubleCheckLock.class){
        if (Objects.isNull(instance)) {
          // 多线程环境下可能出现问题的地方
          instance = new DoubleCheckLock();
        }
      }
    }
  }
}
```
这是经典的单例的双重检测的代码，在单线程环境下并没有什么问题，但是在多线程环境下就可能会有线程安全问题。原因在于某一个线程执行到第一次检测，读取到的instance不为null，instance的引用对象可能还没有完成初始化。因为`instance = new DoubleCheckLock()；`可以分为以下三个步骤：
```java
// 伪代码
memory = allocate(); // 1. 分配对象内存空间
instance (memory); // 2. 初始化对象
instance = memory; // 3. 设置instance指向刚才分配的内存地址, 此时 instance != null
```
由于步骤1和步骤2之间可能存在重新排序，如下
```java
memory = allocate(); // 1. 分配对象内存空间
instance = memory;  // 3. 设置instance指向刚才分配的内存地址，此时instance != null， 但是对象还没有完成初始化
instance(memory); //2. 初始化对象
```

而步骤2和步骤3不存在数据依赖关系，而且无论重排前还是重拍后程序执行结果在单线程中都没有改变，因此这种冲排序是允许的，但是在多线程环境下却造成了线程安全问题。当一个线程访问instance不为null时，由于instance实例未必已完成初始化，也就造成了线程安全问题。如何结果，很简单，用`volatile`修饰`instance`就行，这样就组织了指令重排序：
```java
// 禁止指令重排优化
private volatile static DoubleCheckLock instance;
```

> 这个例子有人说有点问题，它们的思路是这样的：
①多个线程同时到达第一层为空判断，此时对象为空，然后开始竞争锁，最终有一个线程胜出，继续执行synchronized代码块里的代码，其他线程阻塞在外；
②胜出的线程继续执行，在同步块里顺利完成对象初始化操作，然后释放锁，这个时候实例对象已经不为空；
③被阻塞的其他线程开始竞争锁，有一个线程胜出，继续执行同步块里的代码，在第二层为空判断时发现对象不为空，立即执行完成，退出同步块并释放锁，返回实例对象；
④剩余的阻塞线程同。
> 这个过程会产生重排序导致的线程非安全么？感觉并不啊，因为发生重新排序的时候只有一个线程在工作啊？
> 刚开始我也是这么想的，后来经过提示：如果`synchornized`加到方法上，那么一定不会存在这个问题，但是仔细观察`synchornized`这个关键字的位置，就会发现背后的玄妙了！
> 试想，一开始有ABC三个线程，一同去请求这个单例，他们首先到达第一层的判空，发现对象为空，此时开始锁竞争，最终胜出，而BC在同步块外面等着。此线程进入了同步块，判空发现还是null。那么进行`instance = new DoubleCheckLock()`，就是上述三个子过程，如果发生了指令重排，当进行到`instance = memory`之后，此时`instance != null`已经是true了。此时线程D也来请求这个单例，它停在第一个判空操作那里，发现`instance != null`为`true`，所以就直接返回这个单例，但是！这个A线程还没有来得及初始化呢！所以D线程用着这个单例一定会出错！这就是为什么需要volatile来禁止指令重排的原因了。

> unsafe.putOrderedXXX()只阻挡指令重排，不保证内存一致性。但是性能比volatile好。本文介绍了一种它的适用场景——需要确保写入B之前A一定已经写入完成了，但是不需要写A和B的结果立即被另一线程看见，则适用它。




参考
* [全面理解Java内存模型(JMM)及volatile关键字](https://blog.csdn.net/javazejian/article/details/72772461 )
* [Java并发编程：volatile关键字解析](https://www.cnblogs.com/dolphin0520/p/3920373.html)
* [JVM内存模型、指令重排、内存屏障概念解析](https://www.cnblogs.com/chenyangyao/p/5269622.html)
