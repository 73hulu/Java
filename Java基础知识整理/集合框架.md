# 集合框架
<!--  toc -->
<!-- tocstop -->

## 概述
在Java2之前，Java是没有完整的集合框架的。只有一些简单的可以自扩容的容器类，比如`Vector`、`Stack`、`HashTable`等，这些容器类在使用中饱受诟病，所以在Java2中被重新设计，于是有了现在的集合框架，需要注意的是，原来的那些容器类并没有被抛弃而是进行了保留，主要的目的是为了向下兼容，即使这样，我们还是应该注意尽量少使用。
Java集合框架涵盖众多数据结构类，其结构图如下：

![java_container](http://ovn0i3kdg.bkt.clouddn.com/Java%E9%9B%86%E5%90%88%E7%B1%BB.png)
>一般用接口定义框架；用抽象类提供接口的一部分实现；用抽象类通过具体的数据结构实现整个接口。

> JDK1.8 [集合框体系](https://docs.oracle.com/javase/8/docs/technotes/guides/collections/reference.html)
从上面的集合框架图可以看出，Java集合框架主要包括两种类型的容器：
1. `集合Collection`：存储一个元素集合,`Collection`接口又有3种子类型的接口`List`、`Set`、`Queue`，再下面是一些抽象类，再下面是具体的实现类，常用的有`HashSet`、`LinkedHashSet`、`ArrayList`、`LinkedList`等。
2. `图Map`：存储键/值对映射，有两个抽象类`AbstractMap`和`SortedMap`，常用的实现类有`HashMap`、`LinkedHashMap`、`WeakHashMap`等。

## Collection接口
`Collection`接口是处理对象接口的根接口，其中定义了很多对元素进行操作的方法，例如`add`、`remove`、`addAll`、`contains`、`toArray`等。


`Collection`接口有3个子接口：`List`、`Set`、`Queue`，它们各自又有自己的实现类，继承结构如下：

![Collection_interface_tree](http://ovn0i3kdg.bkt.clouddn.com/collection_interface_tree.jpg)

接下来就具体的实现进行学习。

## List接口
`List`接口扩展自`Collection`，可以定义一个** 允许有重复** 的有序集合。从`List`接口中的方法来看，`List`接口主要是增加了面向位置的操作，允许指定位置上操作元素，同时增加了一个能够双向遍历线性表的新列表迭代器 `ListIterator`。`AbstractList`类提供了`List`接口的部分实现，`AbstractSequentialList`扩展自`AbstractList`，主要提供了对链表的支持。
下面介绍`List`接口的两个重要的实现类：数组线性表`ArrayList`和链式线性表`LinkedList`。
###  ArrayList
`ArrayList`直接继承`AbstractList`类，实现`List接口`、`RandomAccess`接口、`Cloneable`接口和`Serializable`接口。

由于实现了`RandomAccess`接口，所以使用for循环遍历比使用迭代器效率更高。

`ArrayList`使用数组存储元素，提供了三种构造方法。需要注意的是，如果是初始化时人为指定容量大小，那么数组空间在初始化的时候就被申请了；如果没有指定大小或者指定大小为0，那么在构造函数中是指数组空间指向了默认空间`DEFAULTCAPACITY_EMPTY_ELEMENTDATA`或`EMPTY_ELEMENTDATA`，其真正的空间分配在第一次插入元素的时候，默认大小是10。

需要注意的是，元素的个数和容量并不是一个概念，方法`size`可得到元素的真实个数，这个数一定小于等于数组容量。当元素个数超过数组容量的时候，数组需要进行扩容。扩容原则是扩容为原来的1.5倍，这个扩容的大小是固定的，不能认为指定。数组不能无限增长，约定数组的最大容量为`Integer.MAX_VALUE - 8`，而实际上数组的最大容量可以达到`Integer.MAX_VALUE`。`ArrayList`类定义了多个与空间容量有关的方法，比如`ensureCapacityInternal`、`ensureExplicitCapacity`和`grow`，三者层层调用，`grow`才是最终绝对扩容容量的方法。所谓的扩容，实际上是重新申请了一块更大的空间，然后将原来的元素复制到新空间中，这一步采取的方法是`Arrays.copyOf`方法。`ArrayList`的数组空间可以自动扩容，却不能自动缩容。但是可以通过`trimToSize`方法进行收缩，使得元素个数正好等于容量，避免空间浪费。

`ArrayList`类有很多常用的方法。例如
1. `add`是最常用的对单元素操作的方法，有两个重载：一个用来追加元素，一个用来添加元素到指定位置，但是建议尽量少使用后面一种重载方法，因为数组的添加和删除操作涉及到元素的移动，频繁的移动简直是噩梦，虽然这种实现是基于`System.arraycopy`实现的，效率相对较高，但是能避免就避免吧。
2. `remove`是为最常用到的对单个元素操作的方法，有两个重载，不同于`add`方法的两个重载， `remove`的两个方法都是单个参数，一个用来删除指定索引上的元素，另一个以Object对象作为参数，用来删除**第一个**与之匹配的元素，需要注意的是，参数是`Object`类型，需要考虑null类型可能造成的空指针异常问题。
3. 对于集合的操作，`ArrayList`定义了三种方法，`addAll`、`removeAll`和`retainAll`。`addAll`重载了两个方法，同样提供了对位置的操作。`removeAll`顾名思义不多做解释。`retainAll`是保留与参数集合相同的那些元素，实际上，`removeAll`和`retainAll`正好是两个相反的实现过程，在源码中都是巧妙地利用了`batchRemove`的方法，利用布尔参数控制某个元素是否保留，比较巧妙，值得学习。
4. `ArrayList`还提供了一些基于位置的操作，比如`get`、`set`、`indexOf`、`lastIndexOf`等。
5. `ArrayList`实现了`Cloneable`接口，所以必须提供`clone`方法，`ArrayList`重写了该方法，但是要注意该方法提供的是浅拷贝，对于得到的拷贝对象的操作可能会影响原来的对象。
6. `ArrayList`的`toArray`方法需要注意，有两个，而我们如果想要得到特定类型的数组，一般的写法是：`String[] array = x.toArray(new String[])`;
7. `ArrayList`实现了`Iterable`接口，所以他必须提供迭代器方法。在`ArrayList`内部分别提供了两种迭代器方法：`iterator`和`listIterator`，前者返回`Iterator`类型迭代器，后者返回`ListIterator`。后者提供了双向迭代方法，比`Iterator`更强大。而两者类型的迭代器的实现是基于`ArrayList`的两个内部类：`Itr`和`ListItr`，前者实现`Iterator`接口，后者实现`ListIterator`接口。我们也可以学习这种方法来自定义自己的迭代器。需要注意的是，`ArrayList`中有一个变量`modCount`，这是用来观测在使用迭代器期间，外部对象是否对集合做出修改，如果做出修改，那么迭代器将不能使用。这个变量实际上就是计数器，记录外部对象修改操作的次数，修改操作例如add、remove、retainAll等。初始化迭代器的时候，会将这个量保存在迭代器的变量`expectedModCount`中，每次迭代器的操作都会先检查这个量和外部对象此时的`modCount`是否相等，不相等则说明发生了非迭代器的操作，那么迭代器操作就不能进行下去。

`ArrayList`可以和数组相互转化。`ArrayList`通过`toArray`方法转为为数组，注意写法，在上面第6条解释过。数组可以通过`Arrays.asList(变长字符串数组)`可以创建字符串线性表，但是需要注意的是，这个方法返回值是`Arrays.ArrayList`，而不是`java.util.ArrayList`。

注意java.util.ArrayList和java.util.Arrays.ArrayList的区别，后者具有 `set()`，`get()`，`contains()`等方法，但是不具有任何添加或移除元素的任何方法。因为该类的大小(size)是固定的。

实际上我们真正创建java.util.ArrayList的写法如下:
```java
ArrayList<String> list = new ArrayList<String>(Arrays.asList(arr));
```
`ArrayList`的构造方法可以接受一个`Collection`类型的对象，而我们的 `java.util.Arrays.ArrayList`正好也是它的一个子类。实际上，更加高效的代码示例是：
```java
ArrayList<String> list = new ArrayList(arr.length);
Collections.addALL(list, Arrays.asList(arr));
```


`ArrayList`是非线程安全的，其方法全部都是非线程安全的。如果要求实现线程安全，那么使用`Vector`或者使用`Collections.synchronizedList`来创建线程安全的`ArrayList`。



###  LinkedList
`LinkedList`类直接继承自抽象父类`AbstractSequentialList`，实现`List`、`Deque`、`Cloneable`和`Serializable`接口。

与`ArrayList`不同，`LinkedList`使用**双向链表**存储数据，所以链表没有初始化大小的概念，也没有空间大小的限制。

由于数据结构的实现是双向链表，所以`LinkedList`提供了一些时间复杂度为O(1)的操作，比如`getFirst`用来获取第一个节点元素，`getLast`用来获取最后一个节点元素，同理还有`removeFirst`、`removeLast`、`addFirst`、`addLast`操作。当然对于插入和删除，`LinkedList`提供了`add`（两种重载），`remove`（两种重载）、`addAll`、`removeAll`操作，这些操作和`ArrayList`提供的方法具有相同的功能。源码实现的时候稍有技巧，如果指定了index，将会比较index是靠近链表头还是链表为，以决定双向链表遍历的方向。

其他线性表的操作与`ArrayList`类似，在此不做赘述。

`LinkedList`采取双向链表的数据结构，使得它实现了栈、单向队列和双线队列的功能。

对于栈的实现，`LinkedList`提供了`pop`和`push`方法，分别对应出栈和入栈操作，实际上，此时链表的头就是栈顶，方法的实现分别依赖于`addFirst`和`removeFirst`方法。

对于单向队列的实现，`LinkedList`提供了`offer`(基于`add`方法)、`poll`（基于`removeFirst`方法）、`remove`方法(基于`removeFirst`方法)、`peek`（基于`getFirst`方法）和`element`（基于`getFirst`）方法。实际上，此时链表头是队头，链表尾是队尾，`offer`方法是真正的入队操作，`poll`和`remove`方法是真正的出队操作，两者的不同点在于前者在遇到空链表的时候返回null，而后者抛出异常。`peek`和`element`方法用来获取队头元素，不出队，两者的不同在于`peek`方法在遇到空队列的时候返回null，而后者抛出异常。

对于双向队列，`LinkedList`提供 `offerFirst`、`offerLast`、`pollFirst`、`pollLast`、`peekFirst`和`peekLast`方法，很容易想的明白具体的实现细节。


> `ArrayList`和 `LinkedList`的不同是由于各自的数据结构不同造成的，即数组和链表的区别。所以在实际使用中我们需要根据特定的需求来选择合适的类：如果经常读取、除了在末尾外不能再其他位置插入或删除元素，则 `ArrayList`效率更高；如果经常插入或删除元素，就选择`LinkedList`。


###  Vector

同步版本的`ArrayList`，现在很少使用。可以使用`Collections.synchronizedList`实现`ArrayList`的同步操作。


### Stack
对于栈操作的抽象，直接继承`Vector`，是栈基于数组的实现。由于数组具有空间的限制，且大部分操作都是在一段进行插入和删除操作，这种特点使用链表来实现更加合适，所以这个类一般不被使用，而是使用`LinkedList`提供的栈操作来代替。


>  对于 `List`，需要说明的是，`List`的顺序是元素插入的顺序，本身不支持有序存储（这里的有序是指大小有序），但是可以利用`Collections`类中的静态方法来实现排序。



## Set接口
`Set`接口扩展自 `Collection`，与`List`的不同之处在于`Set`不允许包含重复元素。即一个规则集内，一定不存在两个相等元素。这一点非常好理解，因为`Set`本身模拟的是数学中“集合”的概念，而集合本身是不能有重复元素的。

`AbstractSet`是一个实现`Set`接口的抽象类。`Set`接口有三个具体实现类：散列集`HashSet`、链式散列集`LinkedHashSet`和树形集`TreeSet`。

### 散列集HashSet
`HashSet`是`Set`接口的最常用的实现类。该类中有一个`HashMap`类型的属性，而集合中的元素保存为`HashMap`的key值。所以说，`HashSet`是基于`HashMap`实现的，这也就能理解，为什么`HashSet`不允许有重复元素，以及最多包含一个null元素。

既然`HashSet`是基于`HashMap`实现的，那就一定存在`HashMap`的容量和装载因子问题，默认情况下，`HashSet`的初始容量为16，默认装载因为为0.75，当使用集合来实例化`HashSet`对象的时候，初始化容量为集合大小的4/3与16中的较大值。`HashSet`有5种重载的构造方法，其中需要注意，三个参数的构造方法中创建的是`LinkedHashMap`的实例，该构造方法的主要用途是为了创建`LinkedHashSet`对象。

###  链式散列集LinkedHashSet
`LinkedHashSet`是用一个链表实现来扩展HashSet类，它支持对规则集内的元素**排序**。需要注意的是，这里的排序说的是按照插入顺序进行排序，并非指按照某种自定义的顺序（比如字典序），进行排序。HashSet中的元素是没有被排序的，而LinkedHashSet中的元素可以按照它们插入规则集的顺序提取。

`LinkedHashSet`是基于`HashSet`实现的，或者从根本来说，是基于`LinkedHashMap`实现的。默认初始化大小为16，默认装载因子为0.75，如果以集合来实例化对象，其初始化大小为2倍的集合大小与11中的较大值。

### 树形集TreeSet
`TreeSet`扩展自AbstractSet，并实现了`SortedSet`，其内部的实现是`NavigableMap`。
在实例化TreeSet时，我们可以给TreeSet指定一个比较器`Comparator`来指定树形集中的元素顺序。树形集中提供了很多便捷的方法。下面是一个`TreeSet`的例子
```java
  public class TestSet {

    public static void main(String[] args) {

        TreeSet<Integer> set = new TreeSet<>();

        set.add(1111);
        set.add(2222);
        set.add(3333);
        set.add(4444);
        set.add(5555);

        System.out.println(set.first()); // 输出第一个元素
        System.out.println(set.lower(3333)); //小于3333的最大元素
        System.out.println(set.higher(2222)); //大于2222的最大元素
        System.out.println(set.floor(3333)); //不大于3333的最大元素
        System.out.println(set.ceiling(3333)); //不小于3333的最大元素

        System.out.println(set.pollFirst()); //删除第一个元素
        System.out.println(set.pollLast()); //删除最后一个元素
        System.out.println(set);
    }
}
```
> 和TreeMap类似，更新一个集合时，如果不需要保持元素的排序关系，应该使用散列集，因为在散列集中插入和删除元素所花的时间少；如果需要保持集合中的元素排序时，可以把散列集转化为树形集。如下:

```java
public class TestHashSet {
	public static void main(String[] args) {
		Set<String> set = new HashSet<String>();

		set.add("London");
		set.add("Paris");
		set.add("New York");
		set.add("New York");
		set.add("San Francisco");

		TreeSet<String> treeSet = new TreeSet<String>(set);
		System.out.println(treeSet);
		for (String string : treeSet) {
			System.out.println(string + " ");
		}
	}
}
```


## Queue接口
`Queue`接口扩展自`Collection`，并提供插入、提取、检验等操作。以下是`Queue` 接口中的全部方法：

![Queue](http://ovn0i3kdg.bkt.clouddn.com/Queue.png)

常用的方法有：
`offer()`表示向队列添加一个元素。
`poll()`与`remove()`方法都是移除队列头部的元素，两者的区别在于如果队列为空，那么poll()返回的是null，而remove()会抛出一个异常。
`element()`与`peek()`主要是获取头部元素，不删除。


### LinnkedList
`LinkedList`实现了`Deque`接口，`Deque`接口，是一个扩展自`Queue`的双端队列，它支持在两端插入和删除元素。`LinkedList`使用双向链表实现了双向队列。
```java
public class TestQueue {

    public static void main(String[] args) {

        Queue<String> queue = new LinkedList<>();

        queue.offer("aaaa");
        queue.offer("bbbb");
        queue.offer("cccc");
        queue.offer("dddd");

        while (queue.size() > 0) {
            System.out.println(queue.remove() + "");
        }
    }
}
```
### PriorityQueue
`PriorityQueue`类实现了一个优先队列，优先队列中元素被赋予优先级，拥有高优先级的先被删除，实际上，这就是一个堆结构。

堆是一个特殊的完全二叉树，满足根节点全部大于或小于左右子树的节点值。`PriorityQueue`使用数组实现该节点，默认为最小堆，如果要创建最大对，可以在创建的时候传入自定义的`Comparator`。需要注意注意的是，`PriorityQueue`禁止null元素，否则抛出空指针异常。

`PriorityQueue`的操作有3种，新建、插入和删除。

`PriorityQueue`的插入可以创建一个新的空优先队列，此时默认的容量为11，默认的比较器为null，即按照自然排序（这也是默认为最小堆的原因）。当然`PriorityQueue`可以进行扩容，当旧容量小于64，扩容时候增加2倍，如果是大容量，那么增加1倍+2的容量。还可以使用已经存在的集合来创建优先队列。如果该集合已经有序，比如`SortedSet`和`PriorityQueue`的实例，则不用进行调整，直接按顺序复制数组即可，前者注意需要排查是否有null元素，有的话抛出异常。如果是非有序数组，那么就不光需要复制数组，还需要进行调整，这个过程是从最后一个节点的父节点开始，不断将以其为根节点的树调整为堆。这个过程和删除节点操作的类似。

`PriorityQueue`的插入操作是将一个节点插入到堆中，注意这时候已经是现成的堆了。我们总是将这个节点插入到最后一个位置，然后沿着其祖先节点的序列找到自己适合的位置：将大于自己的祖先节点下移，直到找到比自己小的节点或者根节点，然后赋值。这个过程叫做"上浮"。

`PriorityQueue`的删除操作可以是将根节点删除（或者软删除，即将其放到数组的末尾，由于size减1，所以之后无法访问到，相当于删除了），其做法是将最后一个元素赋值到根节点中，然后堆就变成了这样的结构：根的左右子树是堆，但是整体不是堆，这时候只需要将根节点与左右子树中较小的那个数交换位置，然后递归循环，直到跟根节点比左右孩子节点值都小或者达到叶子节点。

> 堆的更多内容和演示可参见源码或者算法中的“堆排序”。


## **Map接口**
Map是一种存储键值对映射的容器类，也是集合框架中最最重要没有之一的容器分支。为什么重要？一来是因为存储比较灵活，可以存储任意类型的对象；二来，它能够将查询效率从O(n)提高到O(1)。

`Map`接口是这类容器的根接口，定义了接口的基本特性：键值对中的“键”不能重复，可以为null（由于不能重复，所以最多只能有一个为null的键）；每个键对应了一个"值"，这个值是可以重复的，也可以为null。

`Map`中最基本的元素是映射关系，这里定义了其存储结构是`Entry`接口。这个接口中定义了映射关系的操纵方法，比如获取映射关系的key值`getKey`方法，获取映射关系的value值`getValue`方法，重新赋值方法`setValue`方法，映射比较方法`equals`，获取哈希值的方法`hashcode`等。`Map`的实现类中数据的存储结构必须要实现这个接口。

`Map`中还提供了三种视图及其获取方法：key集合（通过keySet方法），value集合（通过values方法）和key-value集合（通过entrySet方法），注意values方法返回值类型是`Collection`，因为键值对中的值可以重复，而keySet方法和entrySet方法的返回值类型是Set，因为元素必须是唯一的。我们常常利用这三种视图进行Map的遍历，遍历的示例如下：
```java
public static void main(String[] args) {

    Map<Integer, String> map = new HashMap<Integer, String>();
    map.put(1, "a");
    map.put(2, "b");
    map.put(3, "c");
    map.put(4, "d");
    map.put(4, "e");

    System.out.println(map.size());//元素不能重复，所以map大小是4，最后e将覆盖d

    //1. 第一种遍历方法，得到keySet，遍历该Set元素，取得对应的value
    Set<Integer> keySet = map.keySet();
    for (Integer i : keySet){
        System.out.println(i + "=" + map.get(i));
    }

    System.out.println();
    //2. 第二种遍历方法，通过entrySet使用iterator遍历key和value
    Iterator<Map.Entry<Integer, String>> iterator = map.entrySet().iterator();
    while (iterator.hasNext()){
        Map.Entry<Integer, String> entry = iterator.next();
        System.out.println(entry.getKey() + "=" + entry.getValue());
    }

    System.out.println();
    //3. 第三种方法，通过entrySet遍历key和value（推荐使用）
    Set<Map.Entry<Integer, String>> entries = map.entrySet();
    for (Map.Entry<Integer, String> entry : entries){
        System.out.println(entry.getKey() + "=" + entry.getValue());
    }

    //4. 第四种方法，通过values()遍历所有的value，但不能遍历key
    for (String value : map.values()){
        System.out.println(value);
    }

}
```
这里打印出的顺序基本上是按照插入顺序打印的，而实际上，如果插入的更多不同的值，再进行遍历，会发现顺序和插入顺序无关。那是因为`Map`本身对元素的访问顺序并无要求，对元素的访问顺序无任何保证。对元素书序的要求需要在各个实现类中定义，比如`HashMap`对元素访问顺序无任何保证，而`LinkedHashMap`能够包含保证基于插入顺序或基于访问顺序，`TreeMap`能够保证？？？

`Map`的重要实现了有`HashMap`、`LinkedHashMap`、`TreeMap`，它们基于不同的需求，重写了求哈希值、映射关系组成、存储结构、访问顺序等。

> Map接口及其实现类非常非常重要，必须要熟练掌握。

###  HashMap
`HashMap`是非常重要！非常重要！非常重要！几乎是整个`Map`存储框架的核心。

`HashMap`继承自`AbstractMap`，实现`Map`接口。其中内部类`Node`实现了`Map`的内部接口`Entry`，这就是`HashMap`的映射关系的数据结构。`Node`类中定义属性`hash`、`key`、`value`和`next`，分别为哈希值、键、值和下一个映射关系的指针，由于存在指向下一个映射关系的指针，所以可以组成一个单链表，`HashMap`中定义了`Node`类型的数组table，用来存储所有的映射关系。在JDK1.8之前，`HashMap`的内部数据结构设计就是这样——哈希桶 + 单链表，JDK1.8对`HashMap`做出了改进，引入了"红黑树"，即当哈希桶某个位置发生严重（此位置的链表长度大于8）的哈希碰撞，就将哈希桶这个位置上的单链表转化为红黑树，当哈希碰撞不严重（此位置的链表长度小于8），就将该位置上的红黑树转化为单链表。而红黑树的节点的数据结构定义为内部类`TreeNode`，注意，这个内部类继承自`LinkedHashMap`定义的映射关系数据结构`LinkedHashMap.Entry`，因此除了`TreeNode`类型的四个属性：parent、left、right和prev外，还具有`Map.Entry`类型的before、after两个指针。所以对于JDK1.8中的`HashMap`，其数据的存储结构应该是：**数组（哈希桶） + 单项列表 + 红黑树**。

> 单链表的设计是为了解决哈希冲突，所以`HashMap`采取的冲突解决方法是链地址法。

`HashMap`是一种散列存储结构，即根据元素计算得到存储地址。在`HashMap`定义了一个`hash`方法，用key值来计算得到一个哈希值，计算规则是`(key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);`，容易看出，对于key=null，其hash方法的返回值永远是0。然而`hash`方法的返回值实际上是散列函数的输入值，即码值，而散列函数是`(n - 1) & hash`，其中n是table数组的长度。所以这里就能回答为什么`HashMap`最多只能保存一个key=null的映射关系？（因为对于key=null映射关系，计算得到的table中的位置永远是0），以及key=null的映射关系一定被保存在table[0]中。

`HashMap`的实现原理重点在于`putVal`方法，该方法展示了如何插入一个键值对以及如何处理哈希碰撞。首先，判断用来存储数据的table是否已经初始化，如果没有则初始化，此处调用了`HashMap`的容量扩充方法`resize`，在后文会讨论到。接着根据上文所说的计算table中存储位置的方法找到table[i]。如果此时该位置为null，直接new一个Node出来并保存，结束。如果此时该位置为不为null，说明此处已经有人占领了，诶，会不是同样的key呢？所以怀抱这一丝希望，比较一下是否相等。相等的标注是：hash值相同且key相同。如果发现相同，则根据布尔型参数`onlyIfAccess`判断是否需要对映射关系进行值的覆盖，一般情况下，这个参数都是true，即发现相同的key的时候对值进行覆盖。如果不幸发现不相等，此时就发生了哈希碰撞，此时就需要解决哈希冲突。`HashMap`的哈希冲突解决办法是链地址法 + 红黑树：发生冲突的时候，先判断以下当前该槽位上的节点是`Node`类型还是`TreeNode`类型，如果是后者，说明这个位置上的单项链表的长度已经大于某个限定值（默认为8），那么此时又一次发生了哈希冲突，那么只需要在红黑树上再次添加一个节点即可。如果此时table[i]上的节点类型是`Node`，那么新建一个节点添加到单链表尾部，如果此操作之后，链表的长度大于了限定值，需要将链表主转为红黑树。此时已经完成了一大半工作，剩下的一点扫尾的工作是：

①如果发生写入覆盖，那么需要执行`afterNodeAccess`方法，这个方法在`HashMap`中为空，其目的是为了让`HashMap`的继承者能够自定义一些节点访问后的操作，比如`LinkedHashMap`利用该方法实现了LUR式节点访问。

②变量`modCount`自增，与迭代器从操作相关。

③若需要则扩容。

④处理一下节点添加之后的操作，即执行`afterNodeInsertion`方法，与`afterNodeAccess`一样，在`HashMap`中该方法体为空，目的也是为了让其子类自定义功能，比如`LinkedHashMap`覆盖该方法，完成了双向链表的操作。至此，大致完成了`HashMap`的插入节点操作。

以上过程的过程如下：
![HashMap的putVal方法](http://tech.meituan.com/img/java-hashmap/hashMap%20put%E6%96%B9%E6%B3%95%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B%E5%9B%BE.png)


上图总结了`ConcurrentHashMap`总


> 红黑树的相关实现参照`TreeMap`。

前面多次提到扩容的概念，这里做一个总结。与其他容器类一样，`HashMap`同样具有初始容量的概念，这个初始容量就是数组table的大小，默认为16，与其他容器类不同的是，`HashMap`还有一个装载因子的概念，装载因子即数组实际使用个数与总个数的商，默认的阈值为0.75，即我们不必等到数组全部使用完毕才进行扩容，而是在使用到一定程序时候就进行扩容。这个“一定程度”的概念是数组实际使用个数超过装载因子和容量的积（即阈值，用变量`threshold`表示）。而扩容策略是容量加倍，即2 \* oldCap。另外需要注意的是，`HashMap`规定容量大小必须是2的倍数，这一点在方法`tableSizeFor`方法中有体现，比如，如果初始化时定义容量大小为5，那么实际上容量大小将被定义为8。在扩容的同时，需需要将原来table中的Entry对象拷贝到新的table中，在1.7之前，会重新计算每个key的哈希值，然后使用头插法的顺序节点插入到新的索引位置。而在1.8中，很好利用了容量为2次幂且扩容采取2次幂的，那么扩容后**元素的位置要么在原来的位置上，要么在原来的位置上再移动2次幂的位置**的特性，避免了哈希值计算，提高了效率。

与`putVal`相反的是`removeNode`方法。其中涉及到节点操作和链表与红黑树的转化问题。

需要注意，`HashMap`的元素的访问顺序上没有任何保证，既无法保证存储顺序也无法保证访问顺序。如果对元素访问顺序有要求，那么可以使用`LinkedHashMap`和`TreeMap`。

`HashMap`经常用来与`HashTable`来作比较。两者的比较可以从以下几个方面来做比较：
1. 继承关系： `HashMap`继承自`AbstractMap`，而`HashTable`继承自`Dictionary`。
2. 容量大小和扩容策略：`HashMap`默认初始化为16，默认装载因子为0.75，约定容量和阈值必须为2的倍数，扩容策略为2倍，最大空间容量为2^{30};`HashTable`默认初始化容量为11，默认装载因子为0.75，不对容量和阈值做限制，扩容策略是2倍加上1，最大空间容量为`Integer.MAX_VALUE - 8`。
3. 数据存储结构：`HashMap`采取“数组 + 单向链表 + 红黑树” 结构，而`HashTable`采取"数组 + 单项链表"。
4. 解决哈希冲突的方法： `HashMap`采取链地址法，而`Hashtable`采取再散列。
5. 对于null值的允许：`HashMap`允许null值作为key和value，但是只能有一个key=null的键值对;`HashTable`不允许null值作为key和value。
6. 线程安全性：`HashMap`非线程安全，`HashTable`线程安全。

### LinkedHashMap
`LinkedHashMap`继承自`HashMap`，它在`HashMap`的基础上保证了元素的访问顺序，注意是访问顺序（可支持基于插入的访问和基于访问顺序的访问），而不是存储顺序（存储顺序和`HashMap`相同）。

`LinkedList`利用双向链表来维护访问顺序。首先，内部类`Entry`作为映射关系的存储结构，它继承自`HashMap`的映射关系存储结构`Node`，在其基础上增加了前后指正`before`和`after`，这里需要区分这两个指针和`next`指针的关系：这两个指针代表访问关系中的节点关系，而`next`指针代表的是发生哈希冲突的下一个节点，当我们遍历`LinkedHashMap`的时候，实际上是按照双向链表的顺序进行访问，从而保证了访问的有序性。那么，这个双向链表是如何维护的呢？首先，`LinkedHashMap`重写了`newNode`和`newTreeNode`方法：不仅仅创建一个新的节点，更要将这个节点链接到双向链表的末尾，在方法`linkNodeLast`中有所体现。再者，`LinkedHashMap`重写了`afterNodeInsertion`和`afterNodeRemoval`方法，在节点插入和节点删除之后，都重新维护了双向链表。最后，`LinkedHashMap`支持基于访问顺序的访问，即LUR算法，这个依靠`afterNodeAccess`方法实现，其原理是在每次对单个节点进行访问或操作之后，将此节点连接到双向链表的末尾。

所以， `LinkedHashMap`的数据结构实际上是： 数组（哈希桶） + 单项链表 + 红黑树 + 双向链表


### TreeMap
`Treemap`是大名鼎鼎的红黑树的实现，该类实现了`NavigableMap`接口，而该接口实现`SortedMap`接口，所以`TreeMap`能更加灵活地定义元素的排序关系，这种排序关系即BST的排序关系。

红黑树既是一种平衡二叉排序树（AVL），也是一个二叉索引数。其中映射关系定义内部类`Entry`，该类实现`Map.Entry`接口，定义key、value、right、left和parent，其中parent即为二叉索引。

红黑树的主要操作就是节点的插入和删除，分别在`put`和`deleteEntry`方法中定义，两者都是先按照BST的节点插入（新插入节点都是红色节点）和删除进行操作，由于新插入节点和删除节点将破坏红黑树的平衡，所以接下来都需要进行调整和平衡，这部分的操作分别在`fixAfterInsertion`和`fixAfterDeletion`方法中进行。

`fixAfterInsertion`先判断了新节点是否为根节点，是的话直接设置为黑色，算法结束。如果不是，判断其父节点是不是黑色，如果是，不做操作，算法结束。如果还不是，就需要进行接下来的一系列判断，首先判断其叔节点是否为红色，如果是，那么将父节点和叔节点都置为黑色，将祖父节点置为红色，并设其为当前节点，递归进行操作。如果叔叔节点是黑色，如果当前节点是父节点的左节点，父节点是祖父节点的左节点，那么以父节点为轴进行LL旋转，之后将原来的祖父节点置为黑色，将父节点置为红色。如果当前节点是父节点的....（具体的操作看红黑树那一篇博文，在此不再赘述。）

`fixAfterDeletion`对删除节点后的红黑树进行调整和着色，过程比插入更加复杂，仍旧是看红黑树博文和`TreeMap`源码解读，在此不再赘述。

总的来说，在不要求顺序的情况下，`HashMap`的性能最好，所以我们尽量使用`HashMap`进行存储。如果需要特定的存储顺序，我们仍旧先用`HashMap`进行插入，最后构造一个`TreeMap`的实例，再进行操作。这一点和上面的`TreeSet`类似。

### ConcurrentHashMap
`ConcurrentHashMap`是`AbstractMap`的并发实现，设计思想博大精深，内部有50多个内部类，几乎是Java并发编程的精髓所在。在各个版本中有不同实现，尤其在JDK1.8中有很大的改变。

1.8中，`ConcurrentHashMap`的底层存储结构是：哈希桶+单链表+红黑树。这一点和`HashMap`是一致的，但是也存在不一样的地方：
①在基本节点中，`value`和`next`引用都被`volatile`修饰，以来保证可见性和内存屏障。
②在节点中，`setValue`方法直接抛出异常，使用`find`方法来辅助查询。
③在转化为红黑树的过程中，并不是直接使用`TreeNode`来存储数据，而是使用`TreeBin`来进行封装，其中封装了红黑树的一些操作。

`ConcurrentHashMap`的两个重要操作是`put`和`get`操作，分别用来存储数据和获取数据，其中`get`方法是读，不需要加锁，在并发下是安全的。而`put`是写方法，需要并发控制，这也是`ConcurrentHashMap`并发控制的精髓所在。下图是`put`方法的流程图：

![ConcurrentHashMap中put方法执行流程](https://ws3.sinaimg.cn/large/006tNbRwly1fuyn3f433mj31ay10cmz9.jpg)

上图总结了`ConcurrentHashMap`中`put`方法执行的大致流程，其中还有一些细节值得推敲。

`ConcurrentHashMap`保证并发性的原理是`CAS+同步synchornized`，这个1.7中`Segment`锁不相同。

java.util.concurrent包中很多同步的实现是依赖CAS + volatile完成，这一点在ConcurrentHashMap中也能看到很多痕迹，比如基本存储结构`Node`中`value`和`next`使用了`volatile`关键字来保证并发的可见性和内存屏障，而CAS操作主要使用的是`Unsafe`中的一些原子操作，主要有以下3个方法：
```java
// 取得table[i]的值
static final <K,V> Node<K,V> tabAt(Node<K,V>[] tab, int i) {
    return (Node<K,V>)U.getObjectVolatile(tab, ((long)i << ASHIFT) + ABASE);
}
//利用CAS算法设置i位置上的Node节点。之所以能实现并发是因为他指定了原来这个节点的值是多少
//在CAS算法中，会比较内存中的值与你指定的这个值是否相等，如果相等才接受你的修改，否则拒绝你的修改
//因此当前线程中的值并不是最新的值，这种修改可能会覆盖掉其他线程的修改结果  有点类似于SVN
static final <K,V> boolean casTabAt(Node<K,V>[] tab, int i, Node<K,V> c, Node<K,V> v) {
    return U.compareAndSwapObject(tab, ((long)i << ASHIFT) + ABASE, c, v);
}
// 设置table[i]的值，这里没有用compareAndSwapObject，不能保证并发性，在源码中，这个方法用在临界区
static final <K,V> void setTabAt(Node<K,V>[] tab, int i, Node<K,V> v) {
    U.putObjectVolatile(tab, ((long)i << ASHIFT) + ABASE, v);
}
```
> 很容易理解ConcurrentHashMap抛弃Segment锁，但是为什么要使用Synchornized来代替同步锁呢？这个问题的答案可以参考[ConcurrentHashMap(JDK1.8)为什么要放弃Segment](https://blog.csdn.net/mian_CSDN/article/details/70185104)，我认为最主要的原因在于，1.8中synchornized性能得到了提升，并且是JVM级别的，相比于API级别的可重入锁而言，性能高很多。

`ConcurrentHashMap`解决同步问题，也必须面对同步带来的问题。在`ConcurrentHashMap`中，主要采取两种办法来提升同步的性能：
1. 只锁一条单链表
当定位到哈希桶并且需要往单链表/树中插入新节点时，需要锁住头结点，然后安心进行节点新增操作。这样的改进，相较与`HashTable`锁住整个对象、1.7中`ConcurrentHashMap`锁住节点所处Segment的操作，降低了锁粒度，提高了并发度，从而提高了同步性能。这里使用的是JVM级别的`synchornized`关键字，比起API级别的可重入锁，再加上1.8版本的优化，性能自然提升了不少。
2. 协同同步
`HashMap`非线程安全，导致在容器扩容的时候，容易在链表上形成环。而`ConcurrentHashMap`同样面对扩容带来的同步问题。假设有两个线程，一个线程在扩容，另一个在新增节点，这时候会发生什么呢？
`ConcurrentHashMap`中有一个特殊的数据结构——`ForwardingNode`，这是个特殊的标志节点，代表当前该节点所在的单链表正在进行扩容。如果此时一个线程刚好想要对该单链表进行写操作，那么该线程就会协同同步。如何协同？该线程将遍历table，对那些非`ForwardingNode`或null进行扩容，然后将原table中的对应节点置为`ForwardingNode`。注意，这个线程也不是老妈子一样什么都管的，它只管其中分得的一片区域，最少16。等到自己“分内”的事结束之后，就重新进行节点插入。在这个过程中，`sizeCtl`参数记录了协助扩容的线程个数。

这里可能会有一个问题：设置哈希桶中头结点`ForwardingNode`的时机是扩容结束之后。那么对于同一个单链表，如果一个线程正在进行节点新增，另一个线程正在协助扩容，此时该节点还不是`ForwardingNode`，此时自然是可以进行扩容的，这样一来就冲突了？这个问题需要仔细看源码，无论是协助扩容还是节点新增，都使用对头节点进行了同步，所以扩容和节点新增同一时刻只能进行一项。

容器扩容的一个前提是实际的元素个数达到了阈值，在`ConcurrentHashMap`中该阈值是正数的`sizeCtl`。那么如何计算元素个数呢？在`HashTable`中，这个好办，跟GC一样"Stop the World"之后计数，而`HashMap`本身就是线程非安全的。`ConcurrentHashMap`为了性能，不能去“Stop the World”，所以这里的元素个数是估计值并非精确值。`baseCount`和`counterCells`双重保证来计算size。具体参见`ConcurrentHashMap`源码分析章节。

既然`ConcurrentHashMap`设计独具匠心，解决并发又能保证性能，那么它是否能够完全代替`HashTable`或`Collections.synchronizedHashMap`么？答案是否定的。这是因为`HashTable`是操作都是强一致性的，而`ConcurrentHashMap`的`get`、`clear`、`iterator`都是弱一致性的。get方法是弱一致的，是什么含义？可能你期望往`ConcurrentHashMap`底层数据结构中加入一个元素后，立马能对get可见，但`ConcurrentHashMap`并不能如你所愿。换句话说，put操作将一个元素加入到底层数据结构后，get可能在某段时间内还看不到这个元素，若不考虑内存模型，单从代码逻辑上来看，却是应该可以看得到的。

所以如何选择，需要在性能和一致性之间做出平衡。`ConcurrentHashMap`适用于追求性能的场景，大多数线程都只做insert/delete操作，对读取数据的一致性要求较低。



## Collections
`Collections`提供了对于集合的操作，它主要提供了两类方法：对于集合的包装和一些基本的简单算法。

对于集合的包装，`Collections`提供了不可变集合`unmodifiableXXX`、线程安全集合`synchronizedXXX`、类型安全集合`checkedXXX`、空集合`emptyXXX`、单元素集合`singletonXXX`等，注意前三类实际上并未实现真正的不可变、线程安全和类型安全，后面两个方法注意返回的集合都是只读的。

该类中定义了一些简单的算法：排序(sort)、反转(rotate)、二分查找（binarySearch）、混排(shuffle)、填充（fill）、拷贝(copy)、替代（replaceAll）、子串匹配(indexOfSubList和lastIndexOfSubList)、最大(max)、最小(min)。其中每个方法都对随机访问的列表和链表分别做了特殊处理，前者采用索引式存取，后者采取迭代器，提高了效率。这些方法要熟记。

## Arrays
`Arrays`和`Collections`一样是一个工具类，它提供了对于数组的操作，注意和`Array`进行区分。这个类提供了对于数组的常用操作，比如查找、排序、填充等方法。而这个方法提供了对于基本数据类型数组和对象数组的操作，其中对象数组又可以分为一维数组和多维数组，必要的地方对二维数组做了特殊处理，这些特殊方法的名字形式是`deepXXX`。

`Arrays`只提供了`binarySearch`一种查询方法，二分查找方法注意使用前提是有序，注意这个方法中可能会存在整数溢出问题。

`Arrays`提供了`sort`和`parallelSort`两种方法，后者暂且不管，前者非常复杂。

首先，**对于基本数据类型**，在1.7之前采用的是基础快排，1.7之后采用的是优化后的快速排序。算法在`DualPivotQuicksort`类的排序方法中实现。这个类名字可以翻译为“双轴快速排序”，这是一个经过优化后的快速排序然后实际上，并不一定是采用双轴快排的方法。它采取以下策略：
* 当数组的规模较小时，直接插入排序的比较次数并不会比快排或者归并多多少，其效率反而不如简单排序算法，所以在数组规模小于7时，使用**直接插入排序**。
* 当数组规模较大时，合理的选择快排的枢轴元素，如在规模小于40时，在数组的首，中，尾三个位置上的数，取中间大小的数做枢轴；在数组规模大于40时，从数组中取位置均匀分布的9个数，然后每三个数一组取中间数，最后三个中间数再取中间数。确定枢轴后，与数组的第一个元素交换，之后的快排与普通快排一样。  
* 　当数组中有大量重复元素时，选择重复元素作为枢轴，然后两个端各设置两个工作指针`low`、`high`，`left`、`right`用于始终指向要交换的元素位置，如5，2，5，6，4，3，5，1，5，7
　　从high开始判断，low <= high，若high位置的元素 >= 基准元素high–，同时若high位置的元素 == 基准元素，high位置的元素与right位置的元素交换，同时right–，继续直到high位置的元素 < 基准元素。
　　从low开始判断，low <= high，若low位置的元素 <= 基准元素low++，同时若low位置的元素 = 基准元素，low位置的元素与left位置的元素交换，同时left++，继续直到low位置的元素 > 基准元素。
　　low、high位置的元素交换，同时low++、high–，然后再从high开始继续上面的过程，最后将重复的元素至于序列的两端，中间的序列分成了两部分，左面的为小于基准元素的，右面的为大于基准元素的，如5，5，2，1，4，3，7，6，5，5，此时low在7位置，high在3位置。
　　将两端重复的元素都交换到中间后，对两端不等的元素使用快排，左侧外循环从下标0开始判断，若等于枢轴进入内循环，内循环从下标low - 1开始向前找不等于枢轴的，找到交换，直到外循环遇到不等于枢轴的退出；右侧外循环从下标n - 1开始判断，若等于枢轴进入内循环，内循环从下标high + 1开始向后找不等于枢轴的，找到交换，直到外循环遇到不等于枢轴的退出。


另外，**对于引用数据类型数组**，采取过**优化的归并排序算法**。当数组规模较小（小于7）时，使用**直接插入排序**。当属组规模较大时，使用**归并排序**，且当合并的两个有序序列中，低子序列的最高元素小于高子序列的最低元素时，无序执行合并算法，这个可以在merge算法里判断。

> `DualPivotQuicksort.sort`的算法可以计算的上是内排序算法的集大成者，里面的一些优化思路值得节点和学习。


`Arrays`提供了`fill`填充方法，注意对于引用类型数组，这个方法直接将对象赋值给元素。如果这个元素类型是可变类，比如自定义了一个类，那么改变对象参数的值将会导致牵一发而动全身的结果。如果这个元素类型是不可变对象，比如String类，Integer缓存范围内使用valueOf方法得到的对象，那么改变某一个元素将不会影响其他元素。

`Arrays`提供了`copyOf`和`copyOfRange`两种拷贝方法，后者可指定拷贝范围，两者的根本是调用了`System.arraycopy`方法，特别注意这个方法是浅拷贝。

`Arrays`提供了`hashCode`和`deepHashCode`两种计算数组哈希值的方法，后者专门为多维数组服务，对于一维度数组，两者并无差别。这里哈希算法与`String`类一致，即`int hashValue = ∑ hash(A[i]) * 31 ^(n-i)`， 其中hash(A[i])是数组元素本身的哈希值。

`Arrays`提供了`equals`和`deepEquals`两种判断数组相等的方法，后者专门服务于多维数组，对于基本数据类型，相等的含义是“=”，对于引用数据类型，相等的含义是"equals"。

`Arrays`提供了`toString`和`deepToString`两种数组打印方法，区别与上文中相等。注意数组本身的`toString`方法只能得到十六进制值，不能出元素值。

`Arrays`提供`asList`方法，将数组转为`ArrayList`实例，注意该方法的返回结果为`java.util.Arrays.ArrayList`的实例，这个实例没有添加和删除方法，我们如果想要得到`java.util.ArrayList`的实例，可以有以下两种方法：
```java
//方法1： 将asList的结果组作为ArrayList的构造参数
String[] arr = new String[]{"A", "B", "C"};
ArrayList<String> list = new ArrayList(Arrays.asList(arr));

//方法2： 使用Collections.addAll()方法
ArrayList<String> list = new ArrayList(arr.length);
Collections.addAll(list, Arrays.asList(arr));
```
其逆操作是List实例的`toArray`方法。






参考
* [java集合继承关系图](https://www.cnblogs.com/jing99/p/7057245.html)
* [map的遍历的4种方法](http://blog.csdn.net/jianxzjxz/article/details/78803742)
* [Arrays.sort()的内部排序机制](http://blog.csdn.net/zilong0536/article/details/51284017)
* [ java1.8 HahMap的改进](http://blog.csdn.net/seudongnan/article/details/60885223)
* [并发整理（三）— 并发集合类与线程池](https://www.jianshu.com/p/984212792730)
* [ConcurrentHashMap能完全替代HashTable吗？](https://my.oschina.net/hosee/blog/675423)
