# 哈希散列

数据类型按照物理存储方式分为四类：顺序存储、链式存储、散列存储和索引存储。

数组实现顺序存储，能实现O(1)效率的存取，但是必须要求元素连续存储。链式存储不要求连续存储，但是存取的效率是O(n)，对于索引存储，需要额外的空间来保存数据和位置之间的索引关系，存取的效率是O(1)，那么有没有一种实现既省时，又省空间呢？有，这就是散列存储。

>数组本身就是一个散列表

散列，又叫做哈希，主要的思想就是根据节点的关键字能够直接计算出该节点的存储地址。这个过程叫做“散列”，而这种计算方式叫做“散列函数”，用h表示。存放记录的数组叫做散列表(Hash Table)，用HT表示。散列表中的一个位置称为一个槽（slot），散列表HT中的数目用变量M表示，槽从0到M-1标号。

散列的过程就是：根据码值，借助散列函数，计算得到槽的位置，如果产生了散列冲突（就是说计算得到的槽已经被人占了），那就要想办法解决冲突。

所以散列过程有以下三个重要的元素。
## 码值
码值最好能够唯一的标识一个元素。可以是数值，也可以是字符串或者其他类型。我们常常以哈希值作为码值输入，因为它的计算方式已经够复杂以至于能唯一标识一个个体了。不同的对象具有不同的哈希码的计算方法，比如`String`类（忘记的回去复习下），当然我们也可以自己改造，比如`HashMap`就是改造了`hashCode`方法，即内部定义了一个`hash`方法，其计算码值的过程是`key == null ? 0 : (h = key.hashCode() ^ (h >>> 16))`;


## 散列函数

从技术上来说，任何能把所有可能关键码值映射到散列表槽中的函数都是散列函数。下面是一些常用的散列函数
1. 平方取中方法
对于数值类型的码值（比如哈希码），计算码值的平方，然后取中间几位，散列到相应的位置。这样做是因为码值的大多数位或者所有位对结果都有贡献。比如基数是10的四位关键码，散列到长度为100的散列表中，例如码值为4567，其平方值是`4567 * 4567 = 20857489`，取中间两位是57。位数等于`ln100`。
2. 折叠方法
对于字符串类型的输入，计算方法是将每个字符的ASCII值累加起来，对M求模。缺点是，如果和sum比M小，就会产生较差的分布，增加了冲突的机率。
3. 取余

....
>  HashMap中的散列函数关系式是`(n - 1)&hash(key)`，其中n是哈希表的长度。

散列方法有很多，一般都是利用除余、乘法等计算方法。但是散列有好有坏，我们用冲突率来衡量好坏。具体计算这个不多说。

理想的散列方法就是一个萝卜一个坑，一个冲突都没有，但是有些冲突是不可避免的。冲突发生之后，我们如何解决冲突。

## 哈希冲突
解决冲突的方法可以分为两类：开散列方法（Open hashing）和闭散列方法（Closed hashing）。

### 开散列方法
也叫做“单链方法”，Separate chaining，思想就是将冲突记录到表外面。


### 闭散列方法
也叫做“开地址方法”，Open addressing，思路就是讲冲突记录在表内的另一个空槽内。
主要的方法有：桶式散列、线性探查、二次探查、伪随机探查、双散列方法

#### 桶式散列
思想是：将散列表的多个槽(slot)分成多个桶(bucket)，即将M个槽分成B个桶，每个桶中包含M/B个槽。

散列过程是：散列函数把每条记录分配到某个桶中的第一个槽中，如果槽已经被占用了，那么就顺序沿着桶查找，直到找到一个空槽，如果没有槽了，就放到一个无限容量的溢出桶中。
例如有一个散列表，有6个槽，分为3个桶，每个桶2个槽。即`B = 3`，散列函数是：
```java
int h(int i)
{
    return i % B;
}
```
将`9 30 27 4 8`按照顺序放入哈希表中，最后将会变成这样：

![桶式散列](http://ovn0i3kdg.bkt.clouddn.com/%E6%A1%B6%E5%BC%8F%E6%95%A3%E5%88%97.png)

桶式散列的一个变体是：将码值散列到槽中，当槽满的时，再把码值散列扫同一个桶的其他槽中，如果没哟空槽，就散列到溢出桶中。
即散列函数是：
```java
int h(int i)
{
    return i % M;
}
```
仍旧是上面的例子，此时M = 6，同样的顺序结果为：

![桶式散列的变体](http://ovn0i3kdg.bkt.clouddn.com/%E6%95%A3%E5%88%97%E6%A1%B6%E5%8F%98%E4%BD%93.png)


#### 线性探查
比较常用，允许冲突元素记录在散列表中的任何一个空槽。思想是：如果发生了冲突，那么寻找下一个空槽，直到记录被存放。而中间经过的槽的序列叫做冲突解决策略产生的“探查序列”，这个是由“探查函数”产生的。探查函数类似如下：
```java
//@param{i} 第几次探查参数
//@param{k} 码值
int p(int k, int i)
{
    return a * i + b;
}
```
其中a和b是常数，注意该函数返回相对于初始位置的偏移而不是散列表的一个槽。使用的时候如下：
```java
return (h(k)+p(k, i))%M;
```
为了使探查列走遍所有槽，a和M必须互素。
线性探查会导致“基本聚集”这个问题。例如同样使用上面的例子，使用最基本的探查函数`return i`，其中`M = 6`， 对于顺序插入序列`9 30 27 4 8 `，那么9的探查序列是`3 4 5 0 1 2`，而27也是如此，到插入的记录多了，就是大部分都聚到了一起。解决方法就是二次探测或伪随机探查。

#### 二次探查
二次探查的探查函数如下：
```java
int p(int k, int i)
{
    return a*i*i+b*i+c;
}
```
a、b和c都是常数。二次探查的缺点在于，在某种特定情况下，只有特定的槽能被谈查到。比如`M = 3`，`p(k , i) = i * i`。那么散列到槽0的只会探查到0和1，不会探查到2。当散列表长度为素数，以及探查函数为` p(k, i) = i*i` 时，至少能够访问到表中一半的槽。 如果散列表长为` 2 `的指数，并且探查函数为` p(k, i) = (i*i+i)/2` ， 那么表中所有槽都能被探查序列访问到。

#### 伪随机探查
在伪随机探查中，探查序列中的第 i 个槽是 `(h(k) + ri) mod M` ，`ri`是` 1` 到` M-1` 之间的数的随机序列。
所有的插入和检索都使用相同的伪随机序列。

尽管二次探查和伪随机探查能够解决基本聚集问题，然而如果散列函数在某个基槽聚集，依然会保持聚集。这个问题称为二次聚集（secondary clustering）
解决二次聚集问题可以使用双散列方法。

#### 双散列方法
思想就是在探查函数中再增加一个散列方法：
```Java
int p(int k, int i)
{
    return i*h2(k);
}
```
h2 是第二个散列函数
好的双散列实现方法应当保证所有探查序列常数都与表 `M` 长度互素。
其中一种方法是设置 `M` 为素数，而`h2` 返回 `1<=h2<=M-1` 之间的值。
另外一种方法是给定一个 `m` 值，设置 `M = 2^m` ，然后让 `h2` 返回 `1` 到 `2m` 之间的一个奇数值。


## 装填因子
装填因子`α = n / m`，其中n为要散列的元素的个数，m为哈希表的长度。

不同种解决冲突的方法在解决哈希冲突是哈希表的平均查找长度如下：参考[哈希表等概率情况下查找成功和查找不成功的平均查找长度的计算
](http://blog.csdn.net/wangran51/article/details/8826633/)


## 一致性哈希

### 余数哈希的弊端
在分布式环境中，对于服务器集群，一个很重要的问题是路由算法，即我应该去找哪一台机器呢？或者在数据库分表的情况下，应该去找哪一个表呢？这种路由算法常用哈希来做。比较常见的是余数哈希。

比方说，字符串str对应的HashCode是50、服务器的数目是3，取余数得到1，str对应节点Node1，所以路由算法把str路由到Node1服务器上。由于HashCode随机性比较强，所以使用余数Hash路由算法就可以保证缓存数据在整个MemCache服务器集群中有比较均衡的分布。

这种办法在于系统无伸缩性的时候非常好办，但是一旦集群容量不够了，需要扩容的时候，问题就来了。新增的缓存将会破坏原有的哈希规则，所有的数据将需要重新计算规则，然后做数据迁移。比如MemCache服务器集群原来有3台，有20个数据，其哈希值分别是0~19。那么数据的分布就是：

| HashCode | 0 |1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19
| :------------- | :------------- | :------------- | :------------- | :------------- | :------------- | :------------- | :------------- |
| 路由到的服务器 |   0|1|2|0|1|2|0|1|2|0|1|2|0|1|2|0|1|2|0|1|

如果现在机器扩容到了4台，更改服务器列表，仍然使用余数哈希，50对4的余数是2，对于Node2，但是原来str是存储在Node1上的，这就倒置了缓存没有命中。对于以上的例子，增加服务器之后的路由变成下面这样：

| HashCode | 0 |1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19
| :------------- | :------------- | :------------- | :------------- | :------------- | :------------- | :------------- | :------------- |
|路由到的服务器|	0|1|2|**3**|**0**|**1**|**2**|**3**|**0**|**1**|**2**|**3**|0|1|2|**3**|**0**|**1**|**2**|**3**|

加粗的都是没有命中的，占了大多数，这还是简单的情况，而显示情况更加复杂。

以上例子简单地说明了使用余数Hash的路由算法，在扩容的时候会造成大量的数据无法正确命中（其实不仅仅是无法命中，那些大量的无法命中的数据还在原缓存中在被移除前占据着内存）。而缓存存在的目的就是为了缓解数据库的压力，当我们对缓存进行扩容之后，反而降低了命中率，这样不能命中的数据就会去数据库中取得，而数据库的负载能力是以有缓存为前提设计的，这样一来，数据库可能超负荷工作，造成宕机。

针对以上问题，也有办法解决，比如，我们找个访问量低谷的时候，技术人员加班加点扩容然后重启服务器。或者通过模拟请求的方式逐渐预热缓存，使缓存服务器中的数据重新分布。


但是这两种办法都不是好的解决办法，如果每次扩容都来这么一次，技术人员要累死。所以我们要改变哈希策略。

### 一致性哈希
为了解决分布式环境下哈希算法的伸缩性差的问题，MIT提出了分布式哈希（DHT）算法，一致性哈希就是其中一种。
>CARP

一致性Hash算法通过一个叫做“一致性Hash环”的数据结构实现Key到缓存服务器的Hash映射。一致性哈希环的全量大小是2^{32}。其中分布着存储节点和key值的哈希值，范围都是[0, 2^{32} - 1]，根据节点名称的Hash值（其分布为[0, 232-1]）将缓存服务器节点放置在这个Hash环上，然后根据需要缓存的数据的Key值计算得到其Hash值（其分布也为[0, 232-1]），然后在Hash环上顺时针查找距离这个Key值的Hash值最近的服务器节点，完成Key到服务器的映射查找。

![一致性哈希](http://vlambda.com/img?url=https://mmbiz.qpic.cn/mmbiz_png/TufFCFqd0g0P0sdq7MsicABOLAibPF0pU1JKC9DvTJFIqoGJwmfiaLksEDnPt7KCZ6y2IXowAmWRibyGT70nzICzRw/640?wx_fmt=png)

如上如所示，三个存储Node点分别位于Hash环上的三个位置，然后Key值根据其HashCode，在Hash环上有一个固定位置，位置固定下之后，Key就会顺时针去寻找离它最近的一个Node，把数据存储在这个Node的MemCache服务器中。

现在我们来看看哈希环的可伸缩性。如果我们增加了一个节点，如下图中增加了Node4：

![哈希环增加节点](http://vlambda.com/img?url=https://mmbiz.qpic.cn/mmbiz_png/TufFCFqd0g0P0sdq7MsicABOLAibPF0pU1TuUAW8S6VpLc4x021FNWDfYgZnq0PrYq68icFG1aTcq0l1TBRJTGxJA/640?wx_fmt=png)


可以看到，Node4节点的增加，只影响到了一个Key值的数据，本来这个Key值应该是在Node1服务器上的，现在要去Node4了。

所以，采用一致性Hash算法，并不是说对集群没有影响，而是降低了影响。上图中只影响了加粗那一段的数据，相比余数Hash算法影响了远超一半的影响率，这种影响要小得多。更重要的是，集群中缓存服务器节点越多，增加节点带来的影响越小，很好理解。换句话说，**随着集群规模的增大，继续命中原有缓存数据的概率会越来越大，虽然仍然有小部分数据缓存在服务器中不能被读到，但是这个比例足够小，即使访问数据库，也不会对数据库造成致命的负载压力。**

> 注意，当不命中的时候，回去访问数据库，然后将取得的数据写入缓存，在不断的请求之后，这部分的数据就慢慢被迁移到了新的节点中。同理，哈希环在缓存集群收缩的时候，影响也比余数哈希要小。

### 实现一致性哈希
知道了一致性哈希的原理，我们来看看如何实现这种机制。首先需要选取数据结构。

根据哈希环的定义，我们需要构造出一个长度为232的整数环，根据节点名称的Hash值将服务器节点放置在这个Hash环上。整数环应该使用何种数据结构，才能使得运行时的时间复杂度最低？

#### List + 排序
首先想到的是List+排序。算出所有待加入数据结构的节点名称的Hash值放入一个数组中，然后使用某种排序算法将其从小到大进行排序，最后将排序后的数据放入List中，采用List而不是数组是为了结点的扩展考虑。

之后，待路由的结点，只需要在List中找到第一个Hash值比它大的服务器节点就可以了，比如服务器节点的Hash值是[0,2,4,6,8,10]，带路由的结点是7，只需要找到第一个比7大的整数，也就是8，就是我们最终需要路由过去的服务器节点。

如果暂时不考虑前面的排序，那么这种解决方案的时间复杂度：

（1）最好的情况是第一次就找到，时间复杂度为O(1)

（2）最坏的情况是最后一次才找到，时间复杂度为O(N)
平均下来时间复杂度为O(0.5N+0.5)，忽略首项系数和常数，时间复杂度为O(N)。

如果考虑排序，我们知道最好的排序是归并排序，算法复杂度是O(nlogn)。看来排序还是很耗费时间的。

####  List + 遍历
既然排序操作比较耗性能，那么能不能不排序？可以的，所以进一步的，有了第二种解决方案。

解决方案使用List不变，不过可以采用遍历的方式：

（1）服务器节点不排序，其Hash值全部直接放入一个List中

（2）带路由的节点，算出其Hash值，由于指明了”顺时针”，因此遍历List，比待路由的节点Hash值大的算出差值并记录，比待路由节点Hash值小的忽略

（3）算出所有的差值之后，最小的那个，就是最终需要路由过去的节点

在这个算法中，看一下时间复杂度：

1、最好情况是只有一个服务器节点的Hash值大于待路由结点的Hash值，其时间复杂度是O(N)+O(1)=O(N+1)，忽略常数项，即O(N)

2、最坏情况是所有服务器节点的Hash值都大于带路由结点的Hash值，其时间复杂度是O(N)+O(N)=O(2N)，忽略首项系数，即O(N)

所以，总的时间复杂度就是O(N)。其实算法还能更改进一些：给一个位置变量X，如果新的差值比原差值小，X替换为新的位置，否则X不变。这样遍历就减少了一轮，不过经过改进后的算法时间复杂度仍为O(N)。

总而言之，这个解决方案和解决方案一相比，总体来看，似乎更好了一些。

#### BST树
抛开List这种数据结构，另一种数据结构则是使用二叉查找树。

当然我们不能简单地使用二叉查找树，因为可能出现不平衡的情况。平衡二叉查找树有AVL树、红黑树等，这里使用红黑树，选用红黑树的原因有两点：

1、红黑树主要的作用是用于存储有序的数据，这其实和第一种解决方案的思路又不谋而合了，但是它的效率非常高

2、JDK里面提供了红黑树的代码实现TreeMap和TreeSet

另外，以TreeMap为例，TreeMap本身提供了一个tailMap(K fromKey)方法，支持从红黑树中查找比fromKey大的值的集合，但并不需要遍历整个数据结构。

使用红黑树，可以使得查找的时间复杂度降低为O(logN)，比上面两种解决方案，效率大大提升。

> 但是对于插入操作，由于需要维护红黑树，对于插入操作，TreeMap是比较慢的。


### Hash值的重新计算

为什么需要重新计算哈希值？因为对于集群而言，机器的IP连续是非常常见的，如果直接应用字符串的`hashCode`，那么得到的哈希值是非常密集的。这样的话，大部分的key有可能会被映射到同一个node节点上。另外一个问题是，哈希环的地址区间是非负的，而`String`的`hashCode`有可能出现负数。


这种问题也有解决办法，我们干脆改变求解哈希值的算法。这种重新计算Hash值的算法有很多，比如CRC32_HASH、FNV1_32_HASH、KETAMA_HASH等，其中KETAMA_HASH是默认的MemCache推荐的一致性Hash算法，用别的Hash算法也可以，比如FNV1_32_HASH算法的计算效率就会高一些。


### 负载均衡
比如说有Hash环上有A、B、C三个服务器节点，分别有100个请求会被路由到相应服务器上。现在在A与B之间增加了一个节点D，这导致了原来会路由到B上的部分节点被路由到了D上，这样A、C上被路由到的请求明显多于B、D上的，原来三个服务器节点上均衡的负载被打破了。某种程度上来说，这失去了负载均衡的意义，因为负载均衡的目的本身就是为了使得目标服务器均分所有的请求。

这种问题的解决办法是引入虚拟节点。其工作原理是将一个物理节点拆分为多个虚拟节点，并且同一个物理节点的虚拟节点尽量均匀分布在Hash环上。采取这样的方式，就可以有效地解决增加或减少节点时候的负载不均衡的问题。

那么一个节点需要虚拟多少个虚拟节点才能达到负载均衡呢？








参考
* [数据结构和算法分析笔记]散列 hasing](http://blog.51cto.com/sauron/1227923)
* [数据结构：散列（hashing）](http://blog.csdn.net/u014613043/article/details/50726630)
* [五分钟理解一致性哈希算法](http://vlambda.com/wz_wAXQ13eji7.html)
* [漫画算法：什么是一致性哈希？](http://vlambda.com/wz_wK7L8AwmF9.html)
* [经典面试题（二）之一致性哈希算法](http://vlambda.com/wz_wZYR8PU1CD.html)
